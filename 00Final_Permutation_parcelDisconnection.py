# The code was generated by Jie Song, at UNIGE, 2023
# The code was used to do parcel disconnection-based SVR-LSM analysis, 
import numpy as np
import os
import pandas as pd
from sklearn.svm import SVR
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt
import seaborn as sns
import glob
import scipy.io as scio
from tqdm import tqdm
from statsmodels.stats.multitest import fdrcorrection, multipletests
from pandas import DataFrame
import scipy
from scipy.io import loadmat
from os.path import dirname, join as pjoin

# Set random seed for reproducibility
np.random.seed(0)
def linear_model(x, m, c):
    return m * x + c
#reshape the matrix to 1D
output_dir = 'S:\\GVuilleumier\\jies\\20230201_acute_chronic_Neglect_proj\\2_LesionQuantification\\G_Acute'
output_folder=os.path.join(output_dir, 'reshaped_matrix')
if not os.path.exists(output_folder):
    os.makedirs(output_folder)
mat_names = glob.glob('S:\\GVuilleumier\\jies\\20230201_acute_chronic_Neglect_proj\\2_LesionQuantification\\G_Acute\\FCS_*_A\\Parcel_Disconnection\\FCS_*_A_hcp__percent_parcel_SDC.mat')
for mat_name in mat_names:
    file_path = os.path.join(mat_name)
    mat_content=loadmat(pjoin(file_path))
    ini_array=mat_content['pct_sdc_matrix']
    # reshape half of the matrix to 1D
    # for j in range(426):
    #     new_array += list(ini_array[j,0:j+1])
    # reshape the whole matrix to 1D
    # for j in range(426):
    #     new_array += list(ini_array[j,:])
    new_array = ini_array.reshape(-1)
    scio.savemat(pjoin(output_folder, os.path.basename(mat_name)), {'new_array':new_array})
# Function to approximate back-projection for SVR with RBF kernel
def approximate_back_projection(model, support_vectors, gamma):
    dual_coef = model.dual_coef_[0]
    beta_star = sum(dual_coef[i] * support_vectors[i] for i in range(len(dual_coef))) / gamma
    return np.squeeze(beta_star)  # Convert to one-dimensional array

mat_names_1D = glob.glob('S:\\GVuilleumier\\jies\\20230201_acute_chronic_Neglect_proj\\2_LesionQuantification\\G_Acute\\reshaped_matrix\\FCS_*_A_hcp__percent_parcel_SDC.mat')
num_subjects = len(mat_names_1D)
COV_file = 'S:\\GVuilleumier\\jies\\20230201_acute_chronic_Neglect_proj\\2_LesionQuantification\\behaviors\\COV\\Acute_COV.csv'
vector_length = 181476

# Read the X and Y.
Y_paths = [
    'S:\\GVuilleumier\\jies\\20230201_acute_chronic_Neglect_proj\\2_LesionQuantification\\Behaviors\\Acute_F1.csv',
    'S:\\GVuilleumier\\jies\\20230201_acute_chronic_Neglect_proj\\2_LesionQuantification\\Behaviors\\Acute_F2.csv',
    'S:\\GVuilleumier\\jies\\20230201_acute_chronic_Neglect_proj\\2_LesionQuantification\\Behaviors\\Acute_F3.csv'
]

all_Y_list = [pd.read_csv(path) for path in Y_paths]

# Combine all Y dataframes into a single dataframe
all_Y = pd.concat(all_Y_list, axis=1)
label_file = 'S:\\GVuilleumier\\jies\\20230201_acute_chronic_Neglect_proj\\2_LesionQuantification\\HCPex_parcel_name.mat'
label_data = scio.loadmat(label_file)

data_X = np.zeros((num_subjects, vector_length))
COV_df = pd.read_csv(COV_file)
data_x_COV = COV_df.values  # Only covariates, not concatenating with data_X

num = 0
for mat_name in mat_names_1D:
    file_path = os.path.join(mat_name)
    data_x = scio.loadmat(file_path)
    # data_X[num] = data_x['new_array'][:, 0]
    data_X[num] = data_x['new_array']
    num += 1

regression_model = LinearRegression().fit(data_x_COV, data_X)
residuals = data_X - regression_model.predict(data_x_COV)
# Count the number of subjects with values greater than 0 for each feature
num_subjects_positive = np.sum(data_X > 0, axis=0)
# Identify features where at least 4 subjects have values greater than 0
features_to_include = np.where(num_subjects_positive >= 4)[0]

# Filter data_X and residuals to include only selected features
data_X_filtered = data_X[:, features_to_include]
residuals_filtered = residuals[:, features_to_include]

# Perform linear regression to regress out the covariates on filtered data
regression_model_filtered = LinearRegression().fit(data_x_COV, data_X_filtered)
residuals_filtered = data_X_filtered - regression_model_filtered.predict(data_x_COV)

num_permutations = 5000

# Initialize dictionaries to store p-values and significant parcels
p_values_dict = {}
significant_parcels_dict = {}
beta_list = []
p_values = []

# Iterate over each behavior
for behavior, Y_data in all_Y.items():
    data_Y = Y_data.values.ravel()  # Flatten Y data
    
    # Create and fit the SVR model with RBF kernel and specified parameters
    model = SVR(kernel='rbf', C=30.0, epsilon=0.1, max_iter=10000,
                tol=0.001, verbose=True, cache_size=1000, shrinking=True, gamma=5)
    model.fit(residuals_filtered, data_Y)
    
    # Calculate beta map using the approximate back-projection method
    support_vectors = model.support_vectors_
    gamma = model._gamma
    beta = approximate_back_projection(model, support_vectors, gamma)
    beta_list.append(beta) 
    
    # Perform permutations
    for _ in tqdm(range(num_permutations), desc=f"Permutations for {behavior}"):
        np.random.shuffle(data_Y)
        model.fit(residuals_filtered, data_Y)
        support_vectors = model.support_vectors_
        gamma = model._gamma
        permuted_beta = approximate_back_projection(model, support_vectors, gamma)
        
        # Calculate p-values for each parcel
        p_values.append([np.mean(permuted_beta[i] >= beta[i]) for i in range(len(beta))])

    # Calculate average p-values across permutations
    avg_p_values = np.mean(p_values, axis=0)
    significance_threshold = 0.05

    # intialize the array and set to nan
    beta_1D = np.zeros(181476)
    beta_1D[:] = np.nan

    beta_1D[features_to_include] = beta
    scio.savemat(os.path.join(output_folder, f'{behavior}_beta_values.mat'), {'beta_values': beta_1D})

    # reshape the beta_1D (shape = 1*181476) to 2D (426*426) matrix
    beta_2D = np.zeros((426, 426))
    beta_2D = beta_1D.reshape(426, 426)
    scio.savemat(os.path.join(output_folder, f'{behavior}_beta_values_2D.mat'), {'beta_values': beta_2D})

    # 02/08/2024: mask the {behavior}_beta_values_2D.mat, if the p values is greater than 0.05, 
    # set the beta values to 0, save to .mat file
    # Save the beta values corresponding to p-values less than 0.05
    significant_beta_1D = np.copy(beta_1D)
    significant_beta_1D[features_to_include[avg_p_values >= significance_threshold]] = np.nan
    # Reshape the significant_beta_1D (shape = 1*181476) to 2D (426*426) matrix
    significant_beta_2D = np.zeros((426, 426))
    significant_beta_2D = significant_beta_1D.reshape(426, 426)
    scio.savemat(os.path.join(output_folder, f'{behavior}_significant_beta_values_2D.mat'), {'significant_beta_values': significant_beta_2D})
    
    # plot the 2D beta values to a heatmap
    plt.figure()
    sns.heatmap(beta_2D, cmap='jet', xticklabels=False,
            yticklabels=False, annot=False, fmt=".2f", cbar=False)
    plt.savefig(os.path.join(output_dir, f'{behavior}_beta_values_heatmap.png'))
    plt.show()

    # initialize the array and set to nan for p-values
    p_values_1D = np.zeros(181476)
    p_values_1D[:] = np.nan
    p_values_1D[features_to_include] = avg_p_values
    # reshape the p values to 2D matrix
    p_values_2D = np.zeros((426, 426))
    p_values_2D = p_values_1D.reshape(426, 426)
    scio.savemat(os.path.join(output_folder, f'{behavior}_p_values_2D.mat'), {'p_values': p_values_2D})
    
    # plot the p values to a heatmap
    plt.figure()
    sns.heatmap(p_values_2D, cmap='jet_r', xticklabels=False,
            yticklabels=False, annot=False, fmt=".2f", cbar=False)
    plt.savefig(os.path.join(output_dir, f'{behavior}_p_values_heatmap.png'))   
    plt.show()

    # plot the p<0.05 to a heatmap
    plt.figure()
    sns.heatmap(p_values_2D < significance_threshold, cmap='binary', 
                xticklabels=False, yticklabels=False, annot=False, cbar=False)
    plt.savefig(os.path.join(output_dir, f'{behavior}_p_values_less_0.05_heatmap.png'))
    plt.show()

    # Perform FWE correction on p-values
    rejected_null, corrected_p_values, _, _ = multipletests(avg_p_values, method='holm')

    # Save significant parcels and FWE-corrected p-values to CSV
    significant_parcels = np.where(rejected_null)[0]
    significant_parcels_dict[behavior] = significant_parcels
    p_values_dict[behavior] = corrected_p_values

    # intialize the array and set to nan for p-values
    p_values_1D_fwe = np.zeros(181476)
    p_values_1D_fwe[:] = np.nan
    p_values_1D_fwe[features_to_include] = corrected_p_values
    # reshape the p values to 2D matrix
    p_values_2D_fwe = np.zeros((426, 426))
    p_values_2D_fwe = p_values_1D_fwe.reshape(426, 426)
    scio.savemat(os.path.join(output_folder, f'{behavior}_p_values_2D_fwe.mat'), {'p_values': p_values_2D_fwe})
    

    # plot the p values to a heatmap
    plt.figure()
    sns.heatmap(p_values_2D_fwe, cmap='jet_r', xticklabels=False,
            yticklabels=False, annot=False, fmt=".2f", cbar=False)
    plt.savefig(os.path.join(output_dir, f'{behavior}_p_values_heatmap_fwe.png'))
    plt.show()

    